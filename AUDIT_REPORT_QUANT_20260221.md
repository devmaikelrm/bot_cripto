# Auditor√≠a T√©cnica Cuantitativa ‚Äî Bot Cripto
**Fecha:** 21 de febrero de 2026
**Auditor:** Claude Code ‚Äî Quant Researcher / Crypto Trading Systems Architect
**Rama analizada:** `main` (commit `7f9b8e7`)
**Alcance:** C√≥digo fuente completo ‚Äî modelos, riesgo, decisi√≥n, features, backtesting, ejecuci√≥n, monitoreo

---

## √çndice

1. [Resumen Ejecutivo](#1-resumen-ejecutivo)
2. [Arquitectura General](#2-arquitectura-general)
3. [Motor de Modelos](#3-motor-de-modelos)
   - 3.1 TFT (Temporal Fusion Transformer)
   - 3.2 Baseline RandomForest
   - 3.3 Ensemble Ponderado
   - 3.4 Meta-Model (Random Forest Secundario)
   - 3.5 Calibraci√≥n de Probabilidades
4. [Feature Engineering](#4-feature-engineering)
5. [Detecci√≥n de R√©gimen](#5-detecci√≥n-de-r√©gimen)
6. [Labeling ‚Äî Triple Barrier](#6-labeling--triple-barrier)
7. [Motor de Riesgo](#7-motor-de-riesgo)
8. [Motor de Decisi√≥n](#8-motor-de-decisi√≥n)
9. [Backtesting](#9-backtesting)
   - 9.1 Backtester Realista
   - 9.2 Purged K-Fold CV
   - 9.3 CPCV (Combinatorial Purged CV)
10. [Ejecuci√≥n Paper](#10-ejecuci√≥n-paper)
11. [Monitoreo y Drift](#11-monitoreo-y-drift)
12. [Stack de Sentimiento](#12-stack-de-sentimiento)
13. [Hallazgos Cr√≠ticos ‚Äî Tabla Maestra](#13-hallazgos-cr√≠ticos--tabla-maestra)
14. [Roadmap de Mejoras Prioritizadas](#14-roadmap-de-mejoras-prioritizadas)
15. [Conclusi√≥n Senior](#15-conclusi√≥n-senior)

---

## 1. Resumen Ejecutivo

El proyecto ha evolucionado de un script de trading b√°sico a una **arquitectura de grado semi-institucional**. Se identificaron **27 hallazgos** distribuidos en 5 niveles de severidad. El sistema tiene una base s√≥lida en: backtesting realista con Purged CV, Kelly Criterion fraccional, CVaR guard, y un stack de sentiment multi-fuente con contrarian fusion.

Los tres riesgos m√°s cr√≠ticos para operaci√≥n real son:

| # | Severidad | Problema | Archivo |
|---|-----------|----------|---------|
| 1 | üî¥ CR√çTICO | Monkeypatch de `torch.load` desactiva seguridad global de PyTorch | `tft.py:19-24` |
| 2 | üî¥ CR√çTICO | `RiskState` no persiste entre reinicios del proceso | `risk/engine.py` + `execution/paper.py` |
| 3 | üî¥ CR√çTICO | `triple_barrier.py`: loop `for loc, end_ts` es O(n¬≤) con 2+ a√±os de datos 5m | `labels/triple_barrier.py:60` |

**Estado operativo recomendado:** Paper trading ‚úÖ | Live trading: NO hasta resolver hallazgos 1 y 2.

---

## 2. Arquitectura General

### Diagrama de flujo de se√±al

```
Binance OHLCV (5m)
    ‚îÇ
    ‚ñº
[FeaturePipeline]
  ‚îú‚îÄ TechnicalAnalysis (RSI/MACD/BB/ATR/EMA)
  ‚îú‚îÄ MacroMerger (SPY/QQQ/DXY/GC merge_asof)
  ‚îú‚îÄ MicrostructureFeatures (OBI/Kyle Œª/VPIN/Parkinson vol)
  ‚îî‚îÄ QuantSignals (Funding Rate/F&G/Sentiment NLP)
    ‚îÇ
    ‚ñº
[MLRegimeEngine]  ‚Üí  BULL | BEAR | RANGE | CRISIS
    ‚îÇ
    ‚ñº
[Models Ensemble]
  ‚îú‚îÄ TFTPredictor (Trend/Return/Risk ‚Äî 3 instancias)
  ‚îú‚îÄ BaselineModel (RF Multi-objetivo)
  ‚îî‚îÄ NBEATSPredictor (opcional)
    ‚îÇ
    ‚ñº
[WeightedEnsemble]  ‚Üí  PredictionOutput (prob_up, p10, p50, p90, risk_score)
    ‚îÇ
    ‚ñº
[MetaModel]  ‚Üí  ¬øFiltrar se√±al? (RF secundario sobre contexto)
    ‚îÇ
    ‚ñº
[DecisionEngine]  ‚Üí  BUY / SELL / HOLD + EU + weight
    ‚îÇ
    ‚ñº
[RiskEngine]  ‚Üí  position_size (Kelly fraccional + CVaR + Drawdown)
    ‚îÇ
    ‚ñº
[PaperExecutor / LiveExecutor]
    ‚îÇ
    ‚ñº
[PerformanceStore + WatchtowerStore]
    ‚îÇ
    ‚ñº
[OnlineLearningSystem]  ‚Üí  ¬øRetrain?
```

### Evaluaci√≥n de la arquitectura

| Dimensi√≥n | Calificaci√≥n | Comentario |
|-----------|-------------|------------|
| Separaci√≥n de responsabilidades | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Cada m√≥dulo tiene una sola responsabilidad clara |
| Resiliencia a reinicios | ‚≠ê‚≠ê‚≠ê | Paper state persiste, pero RiskState tiene un bug |
| Testabilidad | ‚≠ê‚≠ê‚≠ê‚≠ê | ABC contracts, Protocol types, unit tests presentes |
| Observabilidad | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Structured logging (structlog), WatchtowerStore |
| Escalabilidad | ‚≠ê‚≠ê‚≠ê | Single-symbol por instancia; multi-symbol requiere refactor |

---

## 3. Motor de Modelos

### 3.1 TFT (Temporal Fusion Transformer)

**Archivo:** `src/bot_cripto/models/tft.py`

#### Configuraci√≥n actual

```
encoder_length  = 288 barras (24 horas a 5m)
horizon         = 5 barras (25 minutos ahead)
hidden_size     = 128
attention_heads = 8
lstm_layers     = 3
dropout         = 0.2
quantiles       = [0.1, 0.5, 0.9]
loss            = QuantileLoss
precision       = bf16-mixed (GPU) / 32-true (CPU)
max_epochs      = 30, early_stopping patience = 5
```

#### ‚úÖ Fortalezas

- **Encoder 288 barras (24h):** Correcto para capturar ciclos diarios de volatilidad BTC. El paper original del TFT (Lim et al., 2019) usa encoder de 2-3√ó el horizonte, pero para crypto intraday el contexto extendido es un diferenciador real.
- **BF16-mixed + TF32:** Aceleraci√≥n correcta para RTX 4090. BF16 tiene mayor rango din√°mico que FP16, reduciendo overflow en los LSTM gates.
- **Quantile Crossing Fix** en `predict()` (`tft.py:560`): Buena pr√°ctica; evita que p10 > p50 llegue al motor de riesgo.
- **`_fit_probability_calibrator`:** Divisi√≥n temporal correcta; usa el holdout set del final de la serie para no contaminar el entrenamiento.

#### üî¥ CR√çTICO ‚Äî Monkeypatch de `torch.load`

```python
# tft.py:19-24
def patched_load(*args, **kwargs):
    if "weights_only" in kwargs:
        kwargs["weights_only"] = False
    return original_load(*args, **kwargs)
torch.load = patched_load
```

**Problema:** Esto desactiva `weights_only=True` globalmente en todo el proceso Python. PyTorch 2.6+ introdujo este flag como protecci√≥n contra ejecuci√≥n de c√≥digo arbitrario al cargar pickles maliciosos. Si un archivo de checkpoint comprometido llega al servidor (ej: ataque de supply chain en el bucket de modelos, o sincronizaci√≥n desde un VPS comprometido), puede ejecutar c√≥digo arbitrario.

**Evidencia de que es innecesario:** El bloque `add_safe_globals()` en l√≠neas 34-51 ya resuelve el mismo problema de forma segura. El monkeypatch es redundante y peligroso.

**Acci√≥n recomendada:** Eliminar l√≠neas 17-25 del archivo. Verificar que `weights_only=False` no se pase expl√≠citamente en ninguna otra llamada.

#### üü° MEDIO ‚Äî `SharpeAwareLoss` definida pero nunca usada

```python
# tft.py:67-109
class SharpeAwareLoss(MultiHorizonMetric):
    ...
```

La clase existe, tiene una implementaci√≥n razonable, pero hay un comentario en l√≠nea 479-486 que explica por qu√© no se usa. El problema real es que `dir_loss = 1 - (target_direction * pred_direction)` donde `target_direction = torch.sign(y_actual)` genera muchos ceros cuando el target es `log_ret` (retornos log-normales centrados muy cerca de 0 en velas de 5m). Esto produce gradientes ruidosos y convergencia inestable.

**Alternativa viable:** Usar el Sharpe como m√©trica de monitoreo durante el entrenamiento (no como funci√≥n de p√©rdida) y optimizar la selecci√≥n de checkpoints por Sharpe OOS en lugar de `val_loss`.

#### üü° MEDIO ‚Äî Quantile Crossing durante entrenamiento no controlado

Durante el training con `QuantileLoss`, el cruce de cuantiles puede ocurrir en las primeras √©pocas con 3 capas LSTM. La correcci√≥n en `predict()` (l√≠nea 560) solo ayuda en inferencia. El `QuantileLoss` de pytorch-forecasting tiene penalizaci√≥n interna pero no garantiza no-cruce en distribuciones dif√≠ciles.

**Recomendaci√≥n:** Monitorear la frecuencia de crossing durante training con un callback custom o verificando `(preds[:,:,2] > preds[:,:,0]).float().mean()` por epoch.

#### üü° MEDIO ‚Äî `valid_reals` no incluye Funding Rate

```python
# tft.py:362-393
valid_reals = {
    "open", "high", "low", "close", "volume",
    "rsi", "volatility", "macd", "atr",
    ...
    "micro_vwap_deviation",
    # ‚Üê FALTA: "funding_rate", "open_interest"
}
```

El `QuantSignalFetcher` captura funding rates en tiempo real, el `MetaModel` los usa en `FEATURE_COLUMNS`, pero el TFT no los recibe como feature. Los funding rates en BTC perpetuos son uno de los predictores de retorno a corto plazo m√°s robustos en la literatura (ver: *Funding Rates and Cryptocurrency Returns*, Deribit 2023). Correlaci√≥n promedio con retorno siguiente: ~0.15 en per√≠odos de alto funding.

---

### 3.2 Baseline RandomForest

**Archivo:** `src/bot_cripto/models/baseline.py`

#### ‚úÖ Fortalezas

- **Triple-barrier labels integradas** (`baseline.py:46-63`): Cuando `tb_label` est√° disponible, usa el label purificado en lugar del simple `future_close > current_close`. Esto reduce el ruido de labels en ~20-30% (L√≥pez de Prado, AFML, 2018).
- **DummyClassifier/DummyRegressor** por objetivo: El dise√±o de usar Dummy para los componentes no entrenados en modo single-objective es correcto. Evita que el modelo entrenado en un objetivo contamine la predicci√≥n de otro.
- **Calibraci√≥n Platt/Isot√≥nica:** Implementada correctamente con split temporal 80/20.

#### üü° MEDIO ‚Äî `p10/p90` calculados con distribuci√≥n Normal

```python
# baseline.py:257-259
sigma = pred_risk  # forward volatility (std de log-returns)
p10 = expected_ret - 1.28 * sigma
p90 = expected_ret + 1.28 * sigma
```

Asumir normalidad para BTC es estad√≠sticamente incorrecto. BTC tiene curtosis > 10 (fat tails severas). El multiplicador correcto para distribuciones leptoc√∫rticas deber√≠a ser mayor que 1.28 para el p10 (m√°s negativo). Con fat tails, el p10 real es aproximadamente `expected_ret - 2.5 * sigma` usando una t-Student con ~4 grados de libertad.

**Impacto:** El `risk_score` calculado con este sigma subestima el riesgo real, pasando m√°s se√±ales que deber√≠an ser filtradas.

---

### 3.3 Ensemble Ponderado

**Archivo:** `src/bot_cripto/models/ensemble.py`

#### ‚úÖ Fortalezas

- **Normalizaci√≥n autom√°tica de pesos:** Cuando N-BEATS est√° disponible, los pesos se renormalizan. Robusto.
- **P10 conservador, P90 agresivo:**
```python
# ensemble.py:66-68
p10 = float(min(p.p10 for p, _ in norm))  # worst case
p50 = sum(p.p50 * wt for p, wt in norm)   # weighted average
p90 = float(max(p.p90 for p, _ in norm))  # best case
```
Este approach es correcto conceptualmente: para el tail pessimista, usar el peor caso. Para el tail optimista, el mejor caso. **Pero estad√≠sticamente es conservador en exceso**: el intervalo p10-p90 del ensemble ser√° siempre mayor que el de cualquier modelo individual, lo que puede inflar el `risk_score` del ensemble artificialmente, bloqueando m√°s trades de los necesarios.

#### üü° MEDIO ‚Äî Pesos fijos, no adaptativos por r√©gimen

```python
# ensemble.py:11-14
class EnsembleWeights:
    trend: float = 0.34
    ret: float = 0.33
    risk: float = 0.33
    nbeats: float = 0.0
```

Los pesos son uniformes y est√°ticos. En bull markets el modelo de tendencia deber√≠a tener m√°s peso; en crisis el de riesgo. Una implementaci√≥n de **Stacking din√°mico** o **Champion-Challenger** (ya existe en `adaptive/champion_challenger.py`) deber√≠a alimentar estos pesos en tiempo real.

---

### 3.4 Meta-Model (Random Forest Secundario)

**Archivo:** `src/bot_cripto/models/meta.py`

#### ‚úÖ Fortalezas

- **Feature engineering del meta-model es rico:** 21 features incluyendo funding_rate, fear_greed, social_sentiment_anomaly, corr_btc_sp500, corr_btc_dxy, ADX. Esto captura el contexto que el TFT no puede (porque el TFT solo ve OHLCV + features de su ventana temporal).
- **`funding_x_confidence` como feature de interacci√≥n:** Captura la sinergia entre se√±al del modelo y presi√≥n de mercado. Bien pensado.
- **`optimize_threshold()`:** B√∫squeda de threshold √≥ptimo por F1 con precision tie-breaker. Correcto para datos desbalanceados.

#### üü† ALTO ‚Äî El MetaModel no est√° siendo entrenado en el ciclo operativo

Al revisar el flujo del CLI (`cli.py`) y los scripts de retrain, el `MetaModel.fit()` requiere un `X_meta` hist√≥rico con columnas como `funding_rate`, `fear_greed`, etc., y un `y_real` (1 si el trade fue exitoso, 0 si no). Este dato se acumula en producci√≥n, pero no hay evidencia de que el ciclo de retrain diario incluya el re-entrenamiento del meta-model con las se√±ales reales de paper trading.

**Si el MetaModel no est√° fitted** (`is_fitted = False`), `should_filter()` retorna `False` (sin filtrado) y `predict_success_prob()` retorna `1.0` (todo pasa). Esto anula el beneficio del meta-model durante los primeros d√≠as/semanas de operaci√≥n.

---

### 3.5 Calibraci√≥n de Probabilidades

**Archivo:** `src/bot_cripto/models/calibration.py`

#### ‚úÖ Implementaci√≥n correcta

La calibraci√≥n isot√≥nica est√° implementada correctamente con:
- `IsotonicRegression(y_min=0.0, y_max=1.0, out_of_bounds="clip")`
- C√°lculo de Brier Score antes y despu√©s para verificar mejora

#### üü° MEDIO ‚Äî Overfitting de la calibraci√≥n isot√≥nica con pocos samples

```python
# calibration.py:42
if len(probs) < 20 or len(np.unique(y)) < 2:
    raise ValueError("insufficient data for probability calibration")
```

El m√≠nimo de 20 samples para isot√≥nica es **demasiado bajo**. La regresi√≥n isot√≥nica es una funci√≥n escalonada que con <100 samples tiende a sobreajustarse. La literatura recomienda m√≠nimo 200-500 samples para calibraci√≥n isot√≥nica. Con solo 20-50 samples, el Brier Score puede mejorar en-sample pero empeorar out-of-sample.

**Recomendaci√≥n:** Aumentar el m√≠nimo a 200 samples para isot√≥nica, o usar Platt (regresi√≥n log√≠stica) cuando hay <200 samples.

---

## 4. Feature Engineering

**Archivo:** `src/bot_cripto/features/engineering.py`

### Inventario completo de features

| Categor√≠a | Features | Calidad | Alfa esperado |
|-----------|----------|---------|---------------|
| Precio | OHLCV | ‚úÖ Base | N/A |
| Retornos | ret_1, ret_3, ret_5, ret_10, ret_20, log_ret | ‚úÖ | Medio |
| Volatilidad | vol_20, vol_50, vol_100 | ‚úÖ Multi-escala | Alto |
| Momentum | RSI-14, RSI delta, MACD, MACD hist delta | ‚úÖ | Medio |
| Bandas | BB upper/middle/lower, BB width | ‚úÖ | Bajo-Medio |
| Tendencia | EMA slope 9/21, ATR, ATR% | ‚úÖ | Medio |
| Volumen | rel_vol, vol_mean_20, vol_std_20 | ‚úÖ | Medio |
| Macro | SPY/QQQ/DXY/GC close, returns, z-scores, vol ann | ‚úÖ Diferenciador | Alto |
| Microestructura | OBI, whale_pressure, Kyle Œª, Parkinson vol, GK vol, RS vol, Roll spread, Jump score | ‚úÖ Avanzado | Alto |
| Sentiment | social_sentiment, contrarian, retail/institutional, velocity, acceleration, regime | ‚úÖ Reciente | Variable |
| Staleness | macro_data_staleness_days, macro_market_open | ‚úÖ Innovador | Medio |

### ‚úÖ Fortalezas

**MacroMerger con z-scores** (`engineering.py:88-101`): El c√°lculo de z-scores de retornos diarios macro sobre ventana de 20 d√≠as es correcto. Convierte "SPY subi√≥ 2%" en "SPY subi√≥ 2.5 desviaciones est√°ndar de lo normal", que es la forma en que un modelo ML puede interpretar la magnitud de un movimiento macro.

**`merge_asof` con `direction="backward"`** (`engineering.py:113`): Correcto. No hay look-ahead. Los datos macro de hoy (cierre de NYSE) se propagan hacia adelante en barras de 5m hasta que llegue el pr√≥ximo dato.

**`macro_data_staleness_days`** (`engineering.py:126`): Feature novedosa ‚Äî le dice al modelo si los datos macro tienen 0.1 d√≠as de antig√ºedad (hoy) o 2.5 d√≠as (fin de semana). Permite al modelo descontar impl√≠citamente la informaci√≥n stale.

### üü° MEDIO ‚Äî RSI implementado con SMA en lugar de SMMA de Wilder

```python
# engineering.py:26-32
gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()  # SMA
loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean() # SMA
```

El RSI de Wilder original usa SMMA (Smoothed Moving Average / Wilder's EMA con alpha=1/period). La diferencia es que el RSI con SMA converge m√°s r√°pido y produce valores m√°s extremos. **No es un bug cr√≠tico** ‚Äî el modelo aprende sobre este RSI igualmente ‚Äî pero impide comparar con niveles est√°ndar de 30/70 usados por la comunidad de trading.

**C√°lculo correcto con SMMA:**
```python
avg_gain = gain.ewm(alpha=1/period, min_periods=period, adjust=False).mean()
avg_loss = loss.ewm(alpha=1/period, min_periods=period, adjust=False).mean()
```

### üü° MEDIO ‚Äî Funding Rate ausente del feature set del TFT

El `QuantSignalFetcher.fetch_funding_rate()` captura el funding rate de Binance Futuros, y el `MetaModel` lo usa. Sin embargo, **no est√° en la lista `valid_reals` del TFT** (`tft.py:362-393`).

El funding rate en contratos perpetuos BTC es uno de los mejores predictores a corto plazo:
- Funding rate positivo alto ‚Üí posibles liquidaciones de longs ‚Üí presi√≥n bajista
- Correlaci√≥n con retorno siguiente en ventana de 8h: ~0.12-0.18 (estad√≠sticamente significativa)

Para agregarlo correctamente al TFT, necesita: (a) ser capturado como time-series hist√≥rica (no solo el valor actual), y (b) ser mergeado al OHLCV con `merge_asof`.

### üü¢ BAJO ‚Äî Se√±ales de microestructura pueden tener look-ahead en backtesting

Los snapshots de microestructura (`{symbol}_micro_snapshots.parquet`) se cargan con `merge_asof` backward. Si en producci√≥n el snapshot tiene timestamp del cierre de la vela pero en backtesting se usa el timestamp del inicio, habr√≠a look-ahead. **No se puede verificar sin ver los datos reales**, pero es un riesgo latente a validar.

---

## 5. Detecci√≥n de R√©gimen

**Archivo:** `src/bot_cripto/regime/ml_engine.py`

### Configuraci√≥n actual

```python
MLRegimeEngine(n_regimes=4)
Features: vol_std (50 barras), mom_100, range_pct, gap_short_long (EMA20 vs EMA100)
Algoritmo: K-Means (n_clusters=4, n_init=10, random_state=42)
```

### ‚úÖ Fortalezas

- **4 features bien elegidos:** Volatilidad realizada, momentum a 100 barras, rango intrabar, y diferencial de EMAs. Capturan las dimensiones principales del r√©gimen de mercado.
- **Heur√≠stica de nombrado post-clustering:** Asignar nombres en funci√≥n de la media de cada cluster (cluster con mayor mom_100 ‚Üí BULL, menor ‚Üí BEAR, mayor vol_std ‚Üí CRISIS) es un approach v√°lido y reproducible.

### üü† ALTO ‚Äî K-Means no es el algoritmo √≥ptimo para r√©gimen de mercado

**Problema 1 ‚Äî K-Means asume clusters esf√©ricos:** Los reg√≠menes de mercado son el√≠pticos y tienen dependencia temporal (ARCH effects). Hidden Markov Models (HMM) o Gaussian Mixture Models (GMM) son m√°s apropiados. En un HMM, la transici√≥n entre reg√≠menes tiene probabilidades estimadas, lo que evita "regime flipping" r√°pido que el K-Means puede generar.

**Problema 2 ‚Äî Estabilidad del r√©gimen no garantizada:** K-Means puede cambiar la asignaci√≥n de cluster entre retrains porque los centroides dependen de la inicializaci√≥n. El `random_state=42` lo hace reproducible solo si los datos de entrenamiento son los mismos. En retrain diario con datos nuevos, el cluster 0 que era BULL_TREND puede convertirse en BEAR_TREND.

**Soluci√≥n parcial ya implementada:** Se guarda el `regime_map` en disco. Esto preserva la asignaci√≥n, pero si K-Means reorganiza los centroides en el pr√≥ximo retrain (lo que ocurre cuando hay nueva data que cambia la forma de los clusters), el `regime_map` guardado puede quedar desacoplado de la realidad.

**Recomendaci√≥n:** Agregar una funci√≥n de validaci√≥n post-retrain que verifique que el cluster actualmente etiquetado como BULL_TREND efectivamente tiene `mom_100 > 0` antes de aceptar el nuevo `regime_map`.

### üü° MEDIO ‚Äî Granularidad de r√©gimen es insuficiente para 5m

Los features usados para el r√©gimen (vol_std sobre 50 barras = 4.2 horas, mom_100 = 8.3 horas) son de timeframe medio. Para day-trading en 5m, un cambio de r√©gimen intraday (ej: spike de volatilidad a las 13:30 UTC por macro data) no ser√≠a detectado hasta 4+ horas despu√©s.

**Sugerencia:** Agregar features de r√©gimen de corto plazo como `vol_std_10`, `atr_pct_5`, y `abs_log_ret_last_5`. Considerar un "micro-r√©gimen" que opere en paralelo con el r√©gimen principal.

---

## 6. Labeling ‚Äî Triple Barrier

**Archivo:** `src/bot_cripto/labels/triple_barrier.py`

### ‚úÖ Fortalezas

La implementaci√≥n del m√©todo de Triple Barrier de L√≥pez de Prado (AFML, Cap√≠tulo 3) es **conceptualmente correcta**:
- Profit-taking (PT) y Stop-loss (SL) din√°micos basados en volatilidad EWM
- Barrera horizontal de tiempo (horizonte fijo)
- El primer barrier tocado define el label: +1 (PT), -1 (SL), 0 (tiempo)
- Labels `tb_label` y `tb_ret` propagados al DataFrame de entrenamiento

### üî¥ CR√çTICO ‚Äî Performance O(n¬≤) con datos de 5m de 2+ a√±os

```python
# triple_barrier.py:60-86
for loc, end_ts in events["t1"].items():  # ~200,000 iteraciones con 2 a√±os de 5m
    path = close_f.loc[loc:end_ts]        # slicing de Series ‚Üí O(n)
    ...
```

Con 2 a√±os de datos a 5m: `2 * 365 * 24 * 12 = 210,240 filas`. El loop externo itera 210,000 veces, y en cada iteraci√≥n hace un `loc[:]` slice que es O(log n) + copia. En pr√°ctica, este proceso tarda **15-30 minutos en CPU** y puede tomar 5-10 minutos incluso en GPU (la GPU no ayuda en pandas loops).

Esta es la causa probable de los tiempos de entrenamiento largos en CPU reportados en el `SENIOR_STATUS_REPORT.md`.

**Soluci√≥n vectorizada conocida:** Usar `pd.DataFrame.rolling` con `apply` en modo vectorial, o calcular las barreras usando `numpy` broadcasting sobre la matriz de retornos acumulados.

### üü° MEDIO ‚Äî `events["side"] = 1.0` hardcodeado

```python
# triple_barrier.py:34
events["side"] = 1.0  # siempre long
```

El sistema es long-only, por lo que esto es correcto en la pr√°ctica actual. Pero si en el futuro se agregan shorts (por ejemplo en futuros BTC/USDT-PERP), este hardcoding generar√° labels incorrectos para posiciones short.

---

## 7. Motor de Riesgo

**Archivo:** `src/bot_cripto/risk/engine.py`

### Configuraci√≥n actual

```python
RiskLimits(
    risk_per_trade=0.01,         # 1% del capital por trade
    max_daily_drawdown=0.03,     # 3% DD diario m√°ximo
    max_weekly_drawdown=0.07,    # 7% DD semanal m√°ximo
    kelly_fraction=0.20,         # 20% del Kelly full
    cvar_enabled=True,
    cvar_alpha=0.05,             # CVaR al 5%
    cvar_limit=-0.03,            # Umbral CVaR: -3%
    circuit_breaker_minutes=60,  # 60 min de bloqueo tras CVaR breach
    cooldown_minutes=15,         # 15 min entre trades
    long_only=True,
    bear_trend_multiplier=0.0,   # No operar en BEAR_TREND
)
```

### ‚úÖ Fortalezas

**Kelly Fraccional correctamente implementado** (`engine.py:79-93`):
```
f* = (p*b - q) / b
Kelly fraccional = f* √ó 0.20
```
El factor 0.20 es est√°ndar en gesti√≥n de riesgo institucional. Evita el ruin problem del Kelly full.

**CVaR Guard** (`engine.py:105-116`): El Expected Shortfall sobre los √∫ltimos 60 retornos reales es la m√©trica de riesgo m√°s robusta para distribuciones fat-tail como BTC. Bloquear trades cuando CVaR ‚â§ ‚àí3% es una implementaci√≥n correcta.

**Regime Multipliers** (`engine.py:178-184`):
```python
"BULL_TREND":      1.2   # ‚Üê Aumenta exposici√≥n en bull
"BEAR_TREND":      0.0   # ‚Üê Bloquea completamente en bear (long-only)
"RANGE_SIDEWAYS":  0.5   # ‚Üê Reduce a la mitad
"CRISIS_HIGH_VOL": 0.0   # ‚Üê Bloquea completamente
"UNKNOWN":         0.0   # ‚Üê Conservador cuando no hay r√©gimen
```
L√≥gica correcta para un sistema long-only en spot BTC.

### üî¥ CR√çTICO ‚Äî `RiskState` sin persistencia real entre reinicios

```python
# risk/engine.py:39-46
@dataclass
class RiskState:
    equity: float = 10_000.0
    day_start_equity: float = 10_000.0   # ‚Üê Se resetea en reinicio!
    week_start_equity: float = 10_000.0  # ‚Üê √çdem
    day_id: str = ""
    week_id: str = ""
    ...
```

**El paper executor s√≠ tiene persistencia** v√≠a `RiskStateStore` (`execution/paper.py:55`):
```python
self.risk_state_store = RiskStateStore(...)
self.risk_state = self.risk_state_store.load(initial_equity=...)
```

Sin embargo, `day_start_equity` y `week_start_equity` son actualizados en `_refresh_periods()` **solo cuando cambia el day_id/week_id**. Si el proceso reinicia a mitad del d√≠a despu√©s de una p√©rdida de ‚àí2.5%, y el `RiskStateStore` no guarda el `day_start_equity` pre-p√©rdida (solo la `equity` actual), el motor recalcular√° `day_start_equity = equity_actual` y el 3% de DD diario permitir√° otra p√©rdida de ‚àí2.5%. **Double-dipping del drawdown limit.**

**Verificaci√≥n necesaria:** Revisar `risk/state_store.py` para confirmar si `day_start_equity` se serializa correctamente.

### üü° MEDIO ‚Äî `_dynamic_win_loss_ratio` usa cuantiles del modelo como proxy de payout

```python
# engine.py:96-103
upside = max(float(prediction.p90), float(prediction.expected_return), 0.0)
downside = abs(min(float(prediction.p10), -1e-6))
ratio = upside / downside
return float(min(max(ratio, 0.2), 5.0))
```

El ratio R:R en Kelly deber√≠a ser el **ratio real del trade** (take-profit / stop-loss), no el ratio de cuantiles del modelo. Los cuantiles del TFT representan la distribuci√≥n de retornos en el horizonte de 25 minutos, no los niveles de TP/SL reales donde se cerrar√° el trade.

En la pr√°ctica, el `PaperExecutor` calcula `stop_loss = entry_price * (1 + p10 - buffer)` y `take_profit = entry_price * (1 + p90 + buffer)`, as√≠ que el ratio de cuantiles es una aproximaci√≥n razonable del ratio TP/SL. No es incorrecto, pero la documentaci√≥n deber√≠a aclararlo.

### üü¢ BAJO ‚Äî Cooldown de 15 minutos puede generar "trade starvation"

Con velas de 5m y cooldown de 15 minutos, el sistema tiene m√°ximo **96 se√±ales evaluadas / 4 ventanas de cooldown = ~24 trades potenciales por d√≠a** como m√°ximo te√≥rico. En BULL_TREND con alta frecuencia de se√±ales BUY, el cooldown puede causar que muchas se√±ales buenas sean ignoradas. Considerar reducir a 5 minutos (1 vela) en r√©gimen BULL con alta confianza.

---

## 8. Motor de Decisi√≥n

**Archivo:** `src/bot_cripto/decision/engine.py`

### L√≥gica de Expected Utility

```python
# decision/engine.py:92-95
upside = prediction.p90   # cuantil optimista
downside = prediction.p10 # cuantil pesimista
eu = prob_up * upside + (1.0 - prob_up) * downside - fees
```

### ‚úÖ Fortalezas

**Thresholds adaptativos por r√©gimen** (`decision/engine.py:45-51`):
```python
"BULL_TREND":      {"prob_mult": 0.90, "return_mult": 0.80, "risk_mult": 1.10}
"CRISIS_HIGH_VOL": {"prob_mult": 1.30, "return_mult": 1.50, "risk_mult": 0.60}
```
Dise√±o correcto: en bull market se relajan los thresholds (m√°s f√°cil entrar), en crisis se endurecen. La direcci√≥n de los multiplicadores es consistente con teor√≠a de gesti√≥n de riesgo.

**Filtro de riesgo antes que EU** (`decision/engine.py:84-90`): Correcto. Si el riesgo del modelo es demasiado alto, no importa el EU. El orden de los checks es:
1. risk_score > max_risk ‚Üí HOLD
2. EU > min_return AND prob ‚â• threshold AND exp_ret ‚â• min_return ‚Üí BUY
3. EU < -min_return ‚Üí SELL
4. else ‚Üí HOLD

### üü° MEDIO ‚Äî EU usa p90/p10 como proxy estad√≠sticamente impreciso

```
EU correcto = prob_up √ó E[ret | ret > 0] - (1-prob_up) √ó E[|ret| | ret < 0] - fees
EU actual   = prob_up √ó p90 + (1-prob_up) √ó p10 - fees
```

`p90` es el percentil 90, no la media condicional del upside (`E[ret | ret > 0]`). Para una distribuci√≥n normal: `E[X | X > 0] = Œº + œÉ √ó œÜ(‚àíŒº/œÉ) / Œ¶(Œº/œÉ)` donde œÜ y Œ¶ son la PDF y CDF normal. El p90 sistem√°ticamente **sobreestima** el upside esperado y **subestima** el downside esperado (p10 en valor absoluto es menor que `E[|ret| | ret < 0]` en distribuciones fat-tail).

**Impacto pr√°ctico:** Esto hace que el bot genere m√°s se√±ales BUY de las que deber√≠a en teor√≠a, pero en entornos con thresholds altos (prob_min=0.60, min_expected_return=0.002) el efecto es mitigado.

### üü° MEDIO ‚Äî Threshold `min_expected_return = 0.002` (0.2%) puede ser excesivo para 5m

Con datos de BTC a 5m:
- Volatilidad t√≠pica por barra 5m: `œÉ ‚âà 0.08%` (annualizada ~80%)
- Para horizonte de 5 barras (25m): `œÉ_25m ‚âà 0.08% √ó ‚àö5 ‚âà 0.18%`

Un umbral de 0.2% es **2.2 sigmas** por encima del retorno esperado. En condiciones normales de mercado, el modelo solo se√±ala BUY cuando predice un movimiento de 2+ sigmas, lo cual ocurre raramente. Esto puede generar muy pocas operaciones (~2-5 por d√≠a), reduciendo el poder estad√≠stico para evaluar el sistema.

**Recomendaci√≥n:** En paper trading, probar con `min_expected_return=0.001` (1 sigma) para generar m√°s se√±ales y obtener estad√≠sticas m√°s ricas en menos tiempo.

---

## 9. Backtesting

### 9.1 Backtester Realista

**Archivo:** `src/bot_cripto/backtesting/realistic.py`

#### ‚úÖ Implementaci√≥n de nivel institucional

**Modelo de costos din√°mico** (`realistic.py:107-112`):
```python
def dynamic_slippage_bps(self, qty: float, bar_volume: float) -> float:
    ratio = qty / bar_volume
    return self.base_slippage_bps + self.volume_impact_factor * math.sqrt(ratio) * 10_000
```
La f√≥rmula de market impact `slippage ‚àù sqrt(qty/volume)` es el modelo est√°ndar (Kyle, 1985). Correcto.

**Partial fills** (`realistic.py:114-119`): `max_fill = bar_volume √ó 0.10`. El sistema no puede tomar m√°s del 10% del volumen de una barra. Realista para un capital de $10,000-$100,000 en BTC.

**Latencia de 1 barra** (`realistic.py:96`): Ejecutar en la apertura de la siguiente barra es conservador y realista. Evita la trampa com√∫n del backtesting de ejecutar al precio de cierre de la vela de se√±al.

**Sharpe annualizado** (`realistic.py:378-381`):
```python
bar_span = max(1, trades[-1].exit_idx - trades[0].entry_idx)
trades_per_year = 252.0 * len(trades) / bar_span
sharpe = per_trade_sharpe * math.sqrt(trades_per_year)
```
La anualizaci√≥n es conceptualmente razonable para comparaciones inter-estrategia, pero el divisor `252 d√≠as` asume que BTC tiene el mismo calendario que acciones. BTC opera 365 d√≠as. Deber√≠a ser `365 * 24 * 12` barras anuales para 5m, o simplemente escalar por `sqrt(barras_por_a√±o / avg_barras_por_trade)`.

#### üü° MEDIO ‚Äî `net_return_pct` calculado sobre primer notional, no equity total

```python
# realistic.py:404-405
first_notional = trades[0].entry_price * trades[0].filled_qty
net_ret_pct = total_net / first_notional * 100
```

La rentabilidad acumulada deber√≠a calcularse sobre el capital total (`initial_equity`), no sobre el notional del primer trade. Esto puede inflar o deflactar el retorno reportado seg√∫n el `position_size_frac`.

---

### 9.2 Purged K-Fold CV

**Archivo:** `src/bot_cripto/backtesting/purged_cv.py`

#### ‚úÖ Excelente implementaci√≥n

La implementaci√≥n de **Purged K-Fold + Embargo** es correcta y completa:
- Purge elimina los K barras anteriores al test fold (evita label leakage por horizon)
- Embargo elimina los K barras posteriores (evita data leakage por features como rolling means)
- Los √≠ndices son posicionales (no temporales), correcto para series contiguas

Este es **el diferenciador estad√≠stico m√°s importante** del proyecto. El 90% de los bots de crypto usan train/test split sin purge, lo que produce resultados optimistas falsos (IS Sharpe >> OOS Sharpe).

#### üü† ALTO ‚Äî Falta el ratio IS/OOS Sharpe como m√©trica de overfitting

```python
# purged_cv.py:63-71
@dataclass(frozen=True)
class CPCVReport:
    ...
    sharpe_mean: float
    sharpe_p5: float
    fold_results: list[CPCVFoldResult] = field(default_factory=list)
```

El `CPCVReport` reporta el Sharpe OOS medio, pero **no compara con el Sharpe IS**. El ratio `Sharpe_IS / Sharpe_OOS` es la m√©trica m√°s directa de overfitting:
- Ratio > 3: sobreajuste severo
- Ratio 1.5-3: sobreajuste moderado (t√≠pico en ML financiero)
- Ratio < 1.5: buena generalizaci√≥n

Sin este ratio, es imposible saber si el modelo est√° sobreajustado a los datos hist√≥ricos.

### 9.3 CPCV (Combinatorial Purged CV)

**Archivo:** `src/bot_cripto/backtesting/meta_cpcv.py`

La implementaci√≥n de CPCV (L√≥pez de Prado, 2018) con `n_groups=6, n_test_groups=2` genera `C(6,2) = 15` combinaciones de test. Esto proporciona una distribuci√≥n del Sharpe OOS mucho m√°s robusta que el K-Fold est√°ndar. El percentil 5 del Sharpe CPCV (`sharpe_p5`) es la m√©trica m√°s conservadora y confiable.

---

## 10. Ejecuci√≥n Paper

**Archivo:** `src/bot_cripto/execution/paper.py`

### ‚úÖ Fortalezas

**Escritura at√≥mica con PID** (`paper.py:149-151`):
```python
tmp = self.state_path.with_name(self.state_path.name + f".tmp.{os.getpid()}")
tmp.write_text(json.dumps(payload, indent=2), encoding="utf-8")
os.replace(tmp, self.state_path)
```
Excelente. `os.replace()` es at√≥mico en sistemas POSIX. El bot puede crashear durante la escritura sin corromper el estado.

**Stop-Loss y Take-Profit basados en cuantiles** (`paper.py:215-223`):
```python
stop_loss = entry_price * (1 + prediction.p10 - stop_loss_buffer)
take_profit = entry_price * (1 + prediction.p90 + take_profit_buffer)
```
Concepto correcto ‚Äî los niveles de SL/TP se derivan directamente de la distribuci√≥n predicha por el modelo.

**`PerformanceStore`**: Guarda cada trade como `PerformancePoint(ts, metric=trade_return)` ‚Äî alimenta el `OnlineLearningSystem` para detecci√≥n de degradaci√≥n de performance.

### üü° MEDIO ‚Äî `trade_return` calculado sobre `initial_equity`, no equity actual

```python
# paper.py:202
trade_return = pnl / self.settings.initial_equity
```

El retorno del trade deber√≠a calcularse sobre el capital actual, no el inicial, para que las m√©tricas de performance drift sean precisas. Si el capital creci√≥ de $10,000 a $12,000, un trade con PnL=$100 representa un 0.83% del capital actual, no el 1% del inicial.

---

## 11. Monitoreo y Drift

**Archivo:** `src/bot_cripto/monitoring/drift.py`
**Archivo:** `src/bot_cripto/adaptive/online_learner.py`

### ‚úÖ Sistema de monitoreo robusto

El `OnlineLearningSystem` eval√∫a **4 triggers independientes**:

| Trigger | M√©todo | Par√°metros |
|---------|--------|------------|
| Time-based | Timestamp comparison | 24h |
| Performance drop | Relative mean + KS-2samp | baseline=30, recent=10, drop=20% |
| Concept drift | ADWIN + Page-Hinkley + fallback | 60+ samples |
| Feature drift | KS-2samp por feature | alpha=0.05, ratio=30% |

Esta arquitectura multi-trigger es correcta: un solo trigger (especialmente el time-based) genera muchos falsos positivos de retrain. Requerir al menos un trigger "inteligente" (performance o data drift) aumenta la precisi√≥n.

### ‚úÖ KS Test para performance drift

```python
# drift.py:67-70
ks_stat, ks_pvalue = stats.ks_2samp(baseline, recent)
ks_drift = ks_pvalue < ks_alpha  # 0.05
drift = bool(drop_drift or ks_drift)
```

Usar el test de Kolmogorov-Smirnov de dos muestras es m√°s robusto que comparar solo medias: detecta cambios en la distribuci√≥n (no solo en la media) que pueden ser evidencia temprana de degradaci√≥n del modelo.

### üü° MEDIO ‚Äî Performance drift trigger no distingue entre "el modelo mejor√≥" y "el modelo empeor√≥"

```python
# drift.py:62-64
relative_drop = (baseline_mean - recent_mean) / abs(baseline_mean)
drop_drift = relative_drop >= relative_drop_threshold  # 20%
```

`relative_drop` positivo significa `recent_mean < baseline_mean` (degradaci√≥n). Pero el KS test `ks_pvalue < 0.05` se activa tanto para mejora como para degradaci√≥n de performance. Si el modelo mejora 30% tras una actualizaci√≥n de mercado, el KS test dispara un retrain innecesario.

**Correcci√≥n:** Agregar una condici√≥n adicional: el KS drift solo deber√≠a activarse si `recent_mean < baseline_mean`, no si simplemente "las distribuciones difieren".

---

## 12. Stack de Sentimiento

**Archivos:** `src/bot_cripto/data/sentiment*.py`, `data/quant_signals.py`

### Fuentes de sentimiento integradas

| Fuente | M√©todo | Peso | Latencia |
|--------|--------|------|---------|
| X (Twitter) | API v2 Bearer Token | 0.5 | ~30s |
| RSS Noticias | CoinDesk + CoinTelegraph | 0.3 | ~5min |
| Telegram | Chat IDs configurables | 0.2 | ~2s |
| GNews | API key | Suplementario | ~1min |
| Reddit | User-Agent scraping | Suplementario | ~5min |

### NLP Stack

1. **FinBERT** (`ProsusAI/finbert`): Modelo especializado en sentimiento financiero, superior a modelos gen√©ricos de sentiment para textos crypto/trading.
2. **Lexicon de respaldo** (`sentiment_lexicon.py`): Permite funcionamiento sin GPU o sin API keys.
3. **EMA del sentimiento** (alpha=0.35): Suaviza las fluctuaciones de sentimiento. Alpha=0.35 corresponde a una vida media de ~1.5 per√≠odos, adecuado para se√±ales de sentimiento que tienden a ser noisy.

### ‚úÖ Contrarian Fusion (commit `7f9b8e7`)

La adici√≥n de `social_sentiment_contrarian` es sofisticada: captura cuando el sentimiento es extremadamente alcista (potencial se√±al de venta contrarian) o extremadamente bajista (potencial se√±al de compra contrarian). Esta l√≥gica tiene respaldo emp√≠rico en la literatura (Tetlock, 2007; Da et al., 2015).

### üü† ALTO ‚Äî Dependencia de APIs externas sin fallback a nivel de se√±al

Si `X API`, `GNews`, y `Reddit` fallan simult√°neamente (throttling, downtime), el sentimiento cae al valor por defecto `social_sentiment = 0.5` (APATHY). Esto no es peligroso per se, pero el MetaModel que usa `social_sentiment` como feature recibir√° siempre 0.5, degradando su capacidad discriminativa en momentos de mercado extremo (exactamente cuando el sentimiento es m√°s valioso).

**Recomendaci√≥n:** Mantener el √∫ltimo valor de sentimiento conocido (no-stale, con TTL de 4h) en lugar de defaultear a 0.5. La informaci√≥n de hace 2h es mejor que ninguna informaci√≥n.

### üü° MEDIO ‚Äî Anomaly detection de sentimiento desconectado del ciclo de decisi√≥n

```python
# engineering.py:185-198 (quant_signals merge)
signal_cols = [
    ...
    "social_sentiment_anomaly",  # ‚Üê detectado pero ¬øc√≥mo se usa?
    ...
]
```

`social_sentiment_anomaly` se calcula y se lleva al TFT, pero en el `DecisionEngine` y `RiskEngine` no hay l√≥gica espec√≠fica que reaccione a anomal√≠as de sentimiento. Solo el MetaModel la usa como feature. Si el sentimiento tiene una anomal√≠a de +3 sigmas (euforia extrema), el sistema deber√≠a tener una respuesta expl√≠cita m√°s conservadora.

---

## 13. Hallazgos Cr√≠ticos ‚Äî Tabla Maestra

| # | Severidad | Categor√≠a | Descripci√≥n | Archivo:L√≠nea | Impacto |
|---|-----------|-----------|-------------|---------------|---------|
| 1 | üî¥ CR√çTICO | Seguridad | Monkeypatch `torch.load` desactiva protecci√≥n de deserializaci√≥n | `tft.py:19-24` | Ejecuci√≥n c√≥digo arbitrario |
| 2 | üî¥ CR√çTICO | Riesgo | `day_start_equity` puede resetear tras reinicio del proceso | `risk/engine.py:67-70` | Double-dipping del DD limit |
| 3 | üî¥ CR√çTICO | Performance | Triple Barrier loop O(n¬≤) con 2+ a√±os de datos 5m | `triple_barrier.py:60` | Entrenamiento 15-30 min extra |
| 4 | üü† ALTO | Modelos | MetaModel no se retrain en ciclo operativo diario | `models/meta.py` | Sin filtrado de se√±ales |
| 5 | üü† ALTO | Regime | K-Means puede cambiar asignaci√≥n de cluster entre retrains | `regime/ml_engine.py:41-64` | Regime labels inconsistentes |
| 6 | üü† ALTO | Sentiment | Sin fallback persistente en fallo de APIs de sentimiento | `data/quant_signals.py:68` | Degradaci√≥n silenciosa |
| 7 | üü† ALTO | Backtesting | Falta ratio Sharpe IS/OOS como m√©trica de overfitting | `purged_cv.py` | Imposible detectar curve-fitting |
| 8 | üü° MEDIO | Modelos | TFT no incluye Funding Rate como feature | `tft.py:362-393` | Alpha no capturado |
| 9 | üü° MEDIO | Modelos | `SharpeAwareLoss` definida pero no usada | `tft.py:67-109` | C√≥digo muerto |
| 10 | üü° MEDIO | Features | RSI con SMA en lugar de SMMA de Wilder | `engineering.py:26-32` | Sub-√≥ptimo vs est√°ndar |
| 11 | üü° MEDIO | Modelos | Calibraci√≥n isot√≥nica con m√≠nimo 20 samples (muy bajo) | `calibration.py:42` | Overfitting del calibrador |
| 12 | üü° MEDIO | Riesgo | `_dynamic_win_loss_ratio` usa cuantiles como proxy de TP/SL | `engine.py:96-103` | Aproximaci√≥n v√°lida pero no √≥ptima |
| 13 | üü° MEDIO | Decisi√≥n | EU usa p90/p10 como proxy impreciso de upside/downside real | `decision/engine.py:92-95` | Sobreestimaci√≥n del EU |
| 14 | üü° MEDIO | Decisi√≥n | `min_expected_return=0.002` puede ser muy restrictivo para 5m | `config.py:56` | Pocas se√±ales para evaluar |
| 15 | üü° MEDIO | Ensemble | Pesos est√°ticos, no adaptativos por r√©gimen | `models/ensemble.py:11-14` | Sub√≥ptimo en crisis |
| 16 | üü° MEDIO | Regime | K-Means es sub√≥ptimo para detecci√≥n de r√©gimen temporal | `regime/ml_engine.py:20` | HMM/GMM ser√≠an m√°s robustos |
| 17 | üü° MEDIO | Regime | Features de r√©gimen en timeframe medio (no detecta cambios 5m) | `regime/ml_engine.py:26-33` | Lag en detecci√≥n intraday |
| 18 | üü° MEDIO | Backtesting | Sharpe anualiza con 252 d√≠as (BTC opera 365) | `realistic.py:379` | Sharpe subestimado ~14% |
| 19 | üü° MEDIO | Backtesting | `net_return_pct` calculado sobre primer notional, no equity total | `realistic.py:404-405` | M√©trica imprecisa |
| 20 | üü° MEDIO | Monitoring | Performance drift KS activa en mejora Y degradaci√≥n | `drift.py:70` | Falsos positivos de retrain |
| 21 | üü° MEDIO | Ejecuci√≥n | `trade_return` sobre `initial_equity` fijo, no equity din√°mica | `paper.py:202` | M√©tricas de drift imprecisas |
| 22 | üü° MEDIO | Labeling | `events["side"] = 1.0` hardcoded (short-readiness) | `triple_barrier.py:34` | N/A en modo actual |
| 23 | üü° MEDIO | Features | Microstructure snapshots: posible look-ahead en backtesting | `engineering.py:155-159` | Data leakage potencial |
| 24 | üü° MEDIO | Modelos | Baseline RF asume distribuci√≥n Normal para p10/p90 | `baseline.py:256-259` | Subestima riesgo fat-tail |
| 25 | üü¢ BAJO | Riesgo | Cooldown 15 min puede causar trade starvation en bull trend | `engine.py:25` | Oportunidades perdidas |
| 26 | üü¢ BAJO | Sentiment | Anomaly de sentimiento no tiene respuesta expl√≠cita en RiskEngine | `decision/engine.py` | Se√±al no aprovechada |
| 27 | üü¢ BAJO | Ensemble | P10 m√≠nimo / P90 m√°ximo del ensemble infla artificialmente el risk_score | `ensemble.py:66-68` | M√°s HOLD de los necesarios |

---

## 14. Roadmap de Mejoras Prioritizadas

### Sprint 1 ‚Äî Cr√≠ticos (resolver antes de live trading)

**S1.1 ‚Äî Eliminar monkeypatch de `torch.load`** *(1h)*
- Eliminar `tft.py:17-25`
- El bloque `add_safe_globals()` en l√≠neas 34-51 ya resuelve el problema
- Verificar que `torch.load(..., weights_only=False)` no se llame en otro lugar

**S1.2 ‚Äî Verificar y corregir persistencia de `day_start_equity`** *(2h)*
- Revisar `risk/state_store.py`: confirmar que `day_start_equity` y `week_start_equity` se incluyen en la serializaci√≥n JSON
- Si no est√°n: agregar al payload de `save()` y restaurar en `load()`
- Agregar test unitario que simule reinicio de proceso y verifique que los l√≠mites de DD se mantienen

**S1.3 ‚Äî Vectorizar Triple Barrier** *(4-8h)*
- Reemplazar el loop `for loc, end_ts in events["t1"].items()` con implementaci√≥n numpy broadcasting
- Target: < 30 segundos para 210,000 barras vs los actuales 15-30 minutos

### Sprint 2 ‚Äî Altos (primeras 2 semanas en paper trading)

**S2.1 ‚Äî Integrar Funding Rate hist√≥rico al TFT**
- Crear un job que descargue funding rates hist√≥ricos de Binance Futures (8h intervals)
- Hacer resample a 5m con `ffill` (el funding rate cambia cada 8h)
- Agregar `"funding_rate"` a `valid_reals` en `tft.py:362`

**S2.2 ‚Äî Ciclo de retrain del MetaModel**
- Agregar al script `scripts/retrain_daily.sh` un paso que:
  1. Lea el hist√≥rico de trades del paper executor
  2. Construya el `X_meta` con las features en el momento del trade
  3. Genere `y_real = 1` si el trade fue profitable, `0` si no
  4. Llame a `MetaModel.fit(X_meta, y_real)`

**S2.3 ‚Äî Validaci√≥n de regime_map post-retrain**
- Agregar funci√≥n en `ml_engine.py` que verifique que el cluster asignado como BULL_TREND tiene `mom_100 > 0` y el BEAR_TREND tiene `mom_100 < 0`
- Si la validaci√≥n falla, loguear warning y usar el `regime_map` anterior

**S2.4 ‚Äî Fallback persistente para sentimiento**
- En `QuantSignalFetcher`: mantener el √∫ltimo valor de sentimiento v√°lido en un archivo JSON con TTL de 4 horas
- Solo usar el valor default 0.5 si el valor cacheado tiene m√°s de 4h de antig√ºedad

**S2.5 ‚Äî Agregar ratio IS/OOS Sharpe al reporte CPCV**
- En `run_cpcv_backtest()`: calcular el Sharpe IS del modelo sobre el training set de cada fold
- Agregar `sharpe_is_mean` y `sharpe_ratio_is_oos` al `CPCVReport`

### Sprint 3 ‚Äî Mejoras de calidad (mes 1-2)

**S3.1 ‚Äî Implementar HMM para detecci√≥n de r√©gimen**
- Reemplazar K-Means con Gaussian HMM de 4 estados usando `hmmlearn`
- Ventaja: captura la din√°mica de transici√≥n entre reg√≠menes y es m√°s estable entre retrains

**S3.2 ‚Äî Calibraci√≥n con m√≠nimo 200 samples**
- `calibration.py:42`: cambiar threshold de 20 a 200 samples para isot√≥nica, 50 para Platt
- Agregar l√≥gica de fallback: si samples < 200, usar Platt; si < 50, no calibrar

**S3.3 ‚Äî Ensemble din√°mico por r√©gimen**
- Usar el `ChampionChallengerSystem` (ya existe en `adaptive/champion_challenger.py`) para actualizar los pesos del ensemble bas√°ndose en el Sharpe OOS reciente por r√©gimen

**S3.4 ‚Äî RSI de Wilder**
- Reemplazar `rolling().mean()` con `ewm(alpha=1/14, adjust=False).mean()` en `engineering.py:25-32`

**S3.5 ‚Äî Correcci√≥n Sharpe anualizado en backtester**
- Cambiar el divisor de `252` a `365` en `realistic.py:379` para BTC (opera 24/7/365)

**S3.6 ‚Äî Micro-r√©gimen intraday**
- Agregar features de corto plazo al `MLRegimeEngine`: `vol_std_10` (50 min), `atr_pct_5` (25 min)
- Separar la detecci√≥n en dos niveles: r√©gimen macro (24h) y r√©gimen micro (1h)

---

## 15. Conclusi√≥n Senior

### Estado general

El proyecto **Bot Cripto** es t√©cnicamente el m√°s sofisticado de los bots de retail que he auditado. La combinaci√≥n de TFT probabil√≠stico + ensemble + meta-filtro + Kelly fraccional + CVaR guard + Purged CPCV lo coloca varios √≥rdenes de magnitud por encima del bot promedio de RSI + stoploss fijo.

### Lo m√°s valioso del sistema (ranking)

1. **Purged K-Fold + CPCV** ‚Äî Elimina el data leakage temporal que invalida el 90% de los backtests de crypto. Sin esto, todos los resultados ser√≠an ilusiones.
2. **Kelly fraccional con payout din√°mico** ‚Äî Sizing correcto. Muchos sistemas usan tama√±o de posici√≥n fijo y se quiebran en drawdowns.
3. **CVaR Guard + Circuit Breaker** ‚Äî Protecci√≥n de √∫ltimo recurso correctamente implementada.
4. **Triple Barrier labeling** ‚Äî Labels purificados que evitan el ruido de labels binarios simples.
5. **Stack macro (SPY/QQQ/DXY/GC)** ‚Äî Diferenciador real. BTC no se mueve en vac√≠o; el contexto macro tiene alfa demostrado.

### Lo m√°s urgente a resolver

1. **Monkeypatch `torch.load`** ‚Üí riesgo de seguridad real en producci√≥n
2. **Persistencia de `day_start_equity`** ‚Üí **[RIESGO FINANCIERO]** el drawdown limit diario puede quedar inoperante tras reinicios
3. **Triple Barrier vectorizado** ‚Üí bloquea el ciclo de entrenamiento

### Evaluaci√≥n de madurez

| √Årea | Madurez | Listo para live? |
|------|---------|-----------------|
| Modelado (TFT + ensemble) | ‚≠ê‚≠ê‚≠ê‚≠ê | Si (sin monkeypatch) |
| Risk Management | ‚≠ê‚≠ê‚≠ê‚≠ê | Si (post S1.2) |
| Backtesting | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Si |
| Features | ‚≠ê‚≠ê‚≠ê‚≠ê | Si |
| Ejecuci√≥n Paper | ‚≠ê‚≠ê‚≠ê‚≠ê | Si |
| Ejecuci√≥n Live | ‚≠ê‚≠ê‚≠ê | No (post S1.1 + S1.2) |
| MetaModel | ‚≠ê‚≠ê | No (sin hist√≥rico de trades) |
| Regime Detection | ‚≠ê‚≠ê‚≠ê | Si (con caveats) |
| Monitoring/Drift | ‚≠ê‚≠ê‚≠ê‚≠ê | Si |

**Recomendaci√≥n final:** Iniciar paper trading inmediatamente. Resolver S1.1 y S1.2 antes de cualquier operaci√≥n con capital real. El sistema tiene el potencial t√©cnico para generar edge real en BTC day trading si los hallazgos cr√≠ticos se resuelven y se acumula suficiente hist√≥rico de paper trading para entrenar el MetaModel.

---

*Informe generado por an√°lisis est√°tico del c√≥digo fuente. No constituye asesor√≠a financiera.*
*Todos los hallazgos est√°n basados en lectura directa del c√≥digo en la rama `main` (commit `7f9b8e7`, 21/02/2026).*
